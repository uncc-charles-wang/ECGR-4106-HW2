{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1db95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW 2\n",
    "# Charles Wang\n",
    "# ECGR-4106\n",
    "# Problem 1: Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c387ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d0fc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\"))\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc0417d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  bedrooms  bathrooms  stories  parking     price\n",
       "0  7420         4          2        3        2  13300000\n",
       "1  8960         4          4        4        3  12250000\n",
       "2  9960         3          2        2        2  12250000\n",
       "3  7500         4          2        2        3  12215000\n",
       "4  7420         4          1        2        2  11410000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price'] \n",
    "Newtrain = housing[num_vars] \n",
    "Newtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44dbc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5bd58a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_price = Newtrain[\"price\"].to_numpy(dtype=np.float32)\n",
    "n_samples = output_price.size\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "353deca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([436])\n",
      "torch.Size([109])\n"
     ]
    }
   ],
   "source": [
    "n_val = int(0.2 * n_samples)\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "print(train_indices.size())\n",
    "print(val_indices.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c302b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([109])\n",
      "torch.Size([109, 5])\n"
     ]
    }
   ],
   "source": [
    "t_area = torch.tensor(Newtrain[\"area\"].to_numpy(dtype=np.float32))\n",
    "t_bedrooms = torch.tensor(Newtrain[\"bedrooms\"].to_numpy(dtype=np.float32))\n",
    "t_bathrooms = torch.tensor(Newtrain[\"bathrooms\"].to_numpy(dtype=np.float32))\n",
    "t_stories = torch.tensor(Newtrain[\"stories\"].to_numpy(dtype=np.float32))\n",
    "t_parking = torch.tensor(Newtrain[\"parking\"].to_numpy(dtype=np.float32))\n",
    "t_cost = torch.tensor(output_price)\n",
    "\n",
    "train_t_area = t_area[train_indices]\n",
    "train_t_bedrooms = t_bedrooms[train_indices]\n",
    "train_t_bathrooms = t_bathrooms[train_indices]\n",
    "train_stories = t_stories[train_indices]\n",
    "train_parking = t_parking[train_indices]\n",
    "train_cost = t_cost[train_indices]\n",
    "\n",
    "val_t_area = t_area[val_indices]\n",
    "val_t_bedrooms = t_bedrooms[val_indices]\n",
    "val_t_bathrooms = t_bathrooms[val_indices]\n",
    "val_stories = t_stories[val_indices]\n",
    "val_parking = t_parking[val_indices]\n",
    "val_cost = t_cost[val_indices]\n",
    "\n",
    "t_train_input = torch.stack((train_t_area, train_t_bedrooms, train_t_bathrooms, train_stories, train_parking),dim=1)\n",
    "t_val_input = torch.stack((val_t_area,val_t_bedrooms,val_t_bathrooms,val_stories,val_parking),dim=1)\n",
    "\n",
    "t_train_input_n = t_train_input * 0.1\n",
    "t_val_input_n = t_val_input * 0.1\n",
    "\n",
    "print(val_t_area.shape)\n",
    "print(t_val_input_n.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bae90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = nn.Sequential(\n",
    "    nn.Linear(5, 8), # 5 input features, 8 hidden nodes\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8,1)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(seq_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d83db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed anymore, call nn.MSELoss() instead\n",
    "#def loss_fn(predict, actual):\n",
    "#    squared_diffs = (predict - actual)**2\n",
    "#    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf9df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, tensor_input_train, t_input_val, t_c_train, t_c_val):\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(tensor_input_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "        \n",
    "        t_p_val = model(t_input_val)\n",
    "    \n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch %d, Training Loss %f\" % (epoch, float(loss_train.item())))\n",
    "    print(\"Validation Loss %f\" % (float(loss_val.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b227d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Training Loss 14308388896768.000000\n",
      "Validation Loss 16614875463680.000000\n",
      "Total Time: 161 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([436])) that is different to the input size (torch.Size([436, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/charles/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.perf_counter_ns()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    tensor_input_train = t_train_input_n,\n",
    "    t_input_val = t_val_input_n,\n",
    "    t_c_train = train_cost,\n",
    "    t_c_val = val_cost\n",
    ")\n",
    "\n",
    "end_time = time.perf_counter_ns()\n",
    "total_time_ms = (end_time - start_time) / 1000000\n",
    "\n",
    "print(\"Total Time: %d ms\" % (total_time_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7d0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b73237b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = nn.Sequential(\n",
    "    nn.Linear(5, 8), # 5 input features, 8 hidden nodes\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8,8),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8,8),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8,1)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(seq_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3542269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Training Loss 3626922934272.000000\n",
      "Validation Loss 3184880254976.000000\n",
      "Total Time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.perf_counter_ns()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    tensor_input_train = t_train_input_n,\n",
    "    t_input_val = t_val_input_n,\n",
    "    t_c_train = train_cost,\n",
    "    t_c_val = val_cost\n",
    ")\n",
    "\n",
    "end_time = time.perf_counter_ns()\n",
    "total_time_ms = (end_time - start_time) / 1000000\n",
    "\n",
    "print(\"Total Time: %d ms\" % (total_time_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0fb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Part 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2957f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "data_path = \"../dlwpt-code/p1ch7/\"\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)\n",
    "\n",
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541fc262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade42a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3FA0A33640>,\n",
       " 1,\n",
       " 'automobile')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar10[99]\n",
    "img, label, class_names[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85868685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf8cd34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AutoAugment',\n",
       " 'AutoAugmentPolicy',\n",
       " 'CenterCrop',\n",
       " 'ColorJitter',\n",
       " 'Compose',\n",
       " 'ConvertImageDtype',\n",
       " 'FiveCrop',\n",
       " 'GaussianBlur',\n",
       " 'Grayscale',\n",
       " 'InterpolationMode',\n",
       " 'Lambda',\n",
       " 'LinearTransformation',\n",
       " 'Normalize',\n",
       " 'PILToTensor',\n",
       " 'Pad',\n",
       " 'RandAugment',\n",
       " 'RandomAdjustSharpness',\n",
       " 'RandomAffine',\n",
       " 'RandomApply',\n",
       " 'RandomAutocontrast',\n",
       " 'RandomChoice',\n",
       " 'RandomCrop',\n",
       " 'RandomEqualize',\n",
       " 'RandomErasing',\n",
       " 'RandomGrayscale',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomInvert',\n",
       " 'RandomOrder',\n",
       " 'RandomPerspective',\n",
       " 'RandomPosterize',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomRotation',\n",
       " 'RandomSizedCrop',\n",
       " 'RandomSolarize',\n",
       " 'RandomVerticalFlip',\n",
       " 'Resize',\n",
       " 'Scale',\n",
       " 'TenCrop',\n",
       " 'ToPILImage',\n",
       " 'ToTensor',\n",
       " 'TrivialAugmentWide',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'autoaugment',\n",
       " 'functional',\n",
       " 'functional_pil',\n",
       " 'functional_tensor',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5058734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32bf4881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 32, 32]), torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.ToTensor())\n",
    "tensor_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False, transform=transforms.ToTensor())\n",
    "img_t, _ = tensor_cifar10[99]\n",
    "img_t.shape, img_t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe6591b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_t.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaa28df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32, 50000])\n"
     ]
    }
   ],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "327a4777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff5dedf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3,-1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a70144b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61b04a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, \n",
    "#                                      transform=transforms.Compose([\n",
    "#                                          transforms.ToTensor(),\n",
    "#                                          transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "#                                      ]))\n",
    "#transformed_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False, \n",
    "#                                      transform=transforms.Compose([\n",
    "#                                          transforms.ToTensor(),\n",
    "#                                          transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "#                                      ]))\n",
    "\n",
    "## NOTE: Normalization was not used in the notes!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b6d9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "n_out = 10\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, n_out),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de306f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.984338\n",
      "Epoch: 1, Loss: 2.004023\n",
      "Epoch: 2, Loss: 1.568861\n",
      "Epoch: 3, Loss: 1.414083\n",
      "Epoch: 4, Loss: 1.885217\n",
      "Epoch: 5, Loss: 1.654910\n",
      "Epoch: 6, Loss: 1.451623\n",
      "Epoch: 7, Loss: 1.357305\n",
      "Epoch: 8, Loss: 1.514826\n",
      "Epoch: 9, Loss: 1.566556\n",
      "Epoch: 10, Loss: 1.616546\n",
      "Epoch: 11, Loss: 1.311262\n",
      "Epoch: 12, Loss: 1.550768\n",
      "Epoch: 13, Loss: 1.470764\n",
      "Epoch: 14, Loss: 1.944336\n",
      "Epoch: 15, Loss: 1.746733\n",
      "Epoch: 16, Loss: 1.805690\n",
      "Epoch: 17, Loss: 0.921708\n",
      "Epoch: 18, Loss: 1.445877\n",
      "Epoch: 19, Loss: 1.814167\n",
      "Epoch: 20, Loss: 1.812793\n",
      "Epoch: 21, Loss: 1.357201\n",
      "Epoch: 22, Loss: 1.799151\n",
      "Epoch: 23, Loss: 1.461969\n",
      "Epoch: 24, Loss: 1.203787\n",
      "Epoch: 25, Loss: 2.054612\n",
      "Epoch: 26, Loss: 1.268439\n",
      "Epoch: 27, Loss: 1.009080\n",
      "Epoch: 28, Loss: 1.865624\n",
      "Epoch: 29, Loss: 1.468192\n",
      "Epoch: 30, Loss: 1.700804\n",
      "Epoch: 31, Loss: 0.858734\n",
      "Epoch: 32, Loss: 1.230029\n",
      "Epoch: 33, Loss: 1.174921\n",
      "Epoch: 34, Loss: 1.372039\n",
      "Epoch: 35, Loss: 1.525072\n",
      "Epoch: 36, Loss: 1.231108\n",
      "Epoch: 37, Loss: 1.251689\n",
      "Epoch: 38, Loss: 0.941212\n",
      "Epoch: 39, Loss: 1.746112\n",
      "Epoch: 40, Loss: 1.718624\n",
      "Epoch: 41, Loss: 1.391764\n",
      "Epoch: 42, Loss: 1.200866\n",
      "Epoch: 43, Loss: 1.098675\n",
      "Epoch: 44, Loss: 1.110611\n",
      "Epoch: 45, Loss: 1.099174\n",
      "Epoch: 46, Loss: 1.171541\n",
      "Epoch: 47, Loss: 1.044769\n",
      "Epoch: 48, Loss: 1.122313\n",
      "Epoch: 49, Loss: 1.118501\n",
      "Epoch: 50, Loss: 1.515440\n",
      "Epoch: 51, Loss: 1.073206\n",
      "Epoch: 52, Loss: 1.450681\n",
      "Epoch: 53, Loss: 1.628146\n",
      "Epoch: 54, Loss: 1.346910\n",
      "Epoch: 55, Loss: 1.110492\n",
      "Epoch: 56, Loss: 0.778541\n",
      "Epoch: 57, Loss: 1.198740\n",
      "Epoch: 58, Loss: 1.153736\n",
      "Epoch: 59, Loss: 1.267532\n",
      "Epoch: 60, Loss: 1.135728\n",
      "Epoch: 61, Loss: 0.806113\n",
      "Epoch: 62, Loss: 1.098653\n",
      "Epoch: 63, Loss: 1.303112\n",
      "Epoch: 64, Loss: 0.867452\n",
      "Epoch: 65, Loss: 0.784986\n",
      "Epoch: 66, Loss: 1.271607\n",
      "Epoch: 67, Loss: 1.135939\n",
      "Epoch: 68, Loss: 1.153857\n",
      "Epoch: 69, Loss: 1.181286\n",
      "Epoch: 70, Loss: 0.865911\n",
      "Epoch: 71, Loss: 1.043199\n",
      "Epoch: 72, Loss: 1.352833\n",
      "Epoch: 73, Loss: 1.325887\n",
      "Epoch: 74, Loss: 0.845638\n",
      "Epoch: 75, Loss: 1.471549\n",
      "Epoch: 76, Loss: 1.378874\n",
      "Epoch: 77, Loss: 1.208815\n",
      "Epoch: 78, Loss: 1.112262\n",
      "Epoch: 79, Loss: 1.008155\n",
      "Epoch: 80, Loss: 0.984806\n",
      "Epoch: 81, Loss: 1.179224\n",
      "Epoch: 82, Loss: 1.272682\n",
      "Epoch: 83, Loss: 0.997443\n",
      "Epoch: 84, Loss: 0.981051\n",
      "Epoch: 85, Loss: 0.978633\n",
      "Epoch: 86, Loss: 1.516840\n",
      "Epoch: 87, Loss: 0.909178\n",
      "Epoch: 88, Loss: 0.936424\n",
      "Epoch: 89, Loss: 0.851868\n",
      "Epoch: 90, Loss: 1.119950\n",
      "Epoch: 91, Loss: 0.771345\n",
      "Epoch: 92, Loss: 1.183921\n",
      "Epoch: 93, Loss: 1.381517\n",
      "Epoch: 94, Loss: 1.281599\n",
      "Epoch: 95, Loss: 1.132717\n",
      "Epoch: 96, Loss: 1.614876\n",
      "Epoch: 97, Loss: 0.777419\n",
      "Epoch: 98, Loss: 1.142596\n",
      "Epoch: 99, Loss: 0.642291\n",
      "Epoch: 100, Loss: 0.872090\n",
      "Epoch: 101, Loss: 0.916625\n",
      "Epoch: 102, Loss: 0.925014\n",
      "Epoch: 103, Loss: 0.838125\n",
      "Epoch: 104, Loss: 0.884521\n",
      "Epoch: 105, Loss: 0.836689\n",
      "Epoch: 106, Loss: 0.747647\n",
      "Epoch: 107, Loss: 0.646641\n",
      "Epoch: 108, Loss: 0.889803\n",
      "Epoch: 109, Loss: 0.858276\n",
      "Epoch: 110, Loss: 0.897530\n",
      "Epoch: 111, Loss: 0.835101\n",
      "Epoch: 112, Loss: 0.694064\n",
      "Epoch: 113, Loss: 0.909207\n",
      "Epoch: 114, Loss: 0.891224\n",
      "Epoch: 115, Loss: 0.869519\n",
      "Epoch: 116, Loss: 0.761029\n",
      "Epoch: 117, Loss: 1.029181\n",
      "Epoch: 118, Loss: 0.547750\n",
      "Epoch: 119, Loss: 0.627863\n",
      "Epoch: 120, Loss: 0.706747\n",
      "Epoch: 121, Loss: 0.747651\n",
      "Epoch: 122, Loss: 0.778557\n",
      "Epoch: 123, Loss: 0.978973\n",
      "Epoch: 124, Loss: 0.874757\n",
      "Epoch: 125, Loss: 1.385551\n",
      "Epoch: 126, Loss: 1.046788\n",
      "Epoch: 127, Loss: 1.320653\n",
      "Epoch: 128, Loss: 0.696478\n",
      "Epoch: 129, Loss: 0.781974\n",
      "Epoch: 130, Loss: 0.563379\n",
      "Epoch: 131, Loss: 0.451258\n",
      "Epoch: 132, Loss: 0.890070\n",
      "Epoch: 133, Loss: 0.682642\n",
      "Epoch: 134, Loss: 1.078085\n",
      "Epoch: 135, Loss: 0.906443\n",
      "Epoch: 136, Loss: 0.685183\n",
      "Epoch: 137, Loss: 0.790706\n",
      "Epoch: 138, Loss: 0.457962\n",
      "Epoch: 139, Loss: 1.631225\n",
      "Epoch: 140, Loss: 0.854145\n",
      "Epoch: 141, Loss: 0.624032\n",
      "Epoch: 142, Loss: 0.972220\n",
      "Epoch: 143, Loss: 0.688800\n",
      "Epoch: 144, Loss: 0.653283\n",
      "Epoch: 145, Loss: 0.760226\n",
      "Epoch: 146, Loss: 0.731151\n",
      "Epoch: 147, Loss: 0.859400\n",
      "Epoch: 148, Loss: 0.672071\n",
      "Epoch: 149, Loss: 0.418277\n",
      "Epoch: 150, Loss: 0.874340\n",
      "Epoch: 151, Loss: 0.283110\n",
      "Epoch: 152, Loss: 0.759539\n",
      "Epoch: 153, Loss: 0.540007\n",
      "Epoch: 154, Loss: 0.756741\n",
      "Epoch: 155, Loss: 0.529097\n",
      "Epoch: 156, Loss: 0.553519\n",
      "Epoch: 157, Loss: 0.421348\n",
      "Epoch: 158, Loss: 0.859892\n",
      "Epoch: 159, Loss: 0.456289\n",
      "Epoch: 160, Loss: 0.711681\n",
      "Epoch: 161, Loss: 0.632216\n",
      "Epoch: 162, Loss: 0.569854\n",
      "Epoch: 163, Loss: 0.673411\n",
      "Epoch: 164, Loss: 0.527454\n",
      "Epoch: 165, Loss: 0.475630\n",
      "Epoch: 166, Loss: 0.898269\n",
      "Epoch: 167, Loss: 1.052643\n",
      "Epoch: 168, Loss: 1.145411\n",
      "Epoch: 169, Loss: 1.245196\n",
      "Epoch: 170, Loss: 0.590536\n",
      "Epoch: 171, Loss: 0.540702\n",
      "Epoch: 172, Loss: 0.739457\n",
      "Epoch: 173, Loss: 0.584680\n",
      "Epoch: 174, Loss: 0.650574\n",
      "Epoch: 175, Loss: 1.286791\n",
      "Epoch: 176, Loss: 0.845481\n",
      "Epoch: 177, Loss: 0.374980\n",
      "Epoch: 178, Loss: 0.513819\n",
      "Epoch: 179, Loss: 0.737478\n",
      "Epoch: 180, Loss: 0.997243\n",
      "Epoch: 181, Loss: 0.491396\n",
      "Epoch: 182, Loss: 1.074545\n",
      "Epoch: 183, Loss: 0.907614\n",
      "Epoch: 184, Loss: 0.785166\n",
      "Epoch: 185, Loss: 0.342378\n",
      "Epoch: 186, Loss: 0.682505\n",
      "Epoch: 187, Loss: 0.700571\n",
      "Epoch: 188, Loss: 0.237612\n",
      "Epoch: 189, Loss: 0.420479\n",
      "Epoch: 190, Loss: 0.630745\n",
      "Epoch: 191, Loss: 0.757831\n",
      "Epoch: 192, Loss: 0.569475\n",
      "Epoch: 193, Loss: 0.841595\n",
      "Epoch: 194, Loss: 0.668520\n",
      "Epoch: 195, Loss: 0.346708\n",
      "Epoch: 196, Loss: 0.782945\n",
      "Epoch: 197, Loss: 0.402416\n",
      "Epoch: 198, Loss: 0.334848\n",
      "Epoch: 199, Loss: 0.586481\n",
      "Epoch: 200, Loss: 0.863608\n",
      "Epoch: 201, Loss: 1.157598\n",
      "Epoch: 202, Loss: 0.445643\n",
      "Epoch: 203, Loss: 0.662063\n",
      "Epoch: 204, Loss: 0.609108\n",
      "Epoch: 205, Loss: 0.668787\n",
      "Epoch: 206, Loss: 0.966164\n",
      "Epoch: 207, Loss: 0.495521\n",
      "Epoch: 208, Loss: 0.361989\n",
      "Epoch: 209, Loss: 0.295067\n",
      "Epoch: 210, Loss: 0.340927\n",
      "Epoch: 211, Loss: 0.720778\n",
      "Epoch: 212, Loss: 0.890625\n",
      "Epoch: 213, Loss: 0.476726\n",
      "Epoch: 214, Loss: 0.667482\n",
      "Epoch: 215, Loss: 0.390289\n",
      "Epoch: 216, Loss: 0.680632\n",
      "Epoch: 217, Loss: 0.685344\n",
      "Epoch: 218, Loss: 0.497971\n",
      "Epoch: 219, Loss: 0.384486\n",
      "Epoch: 220, Loss: 0.506504\n",
      "Epoch: 221, Loss: 0.582871\n",
      "Epoch: 222, Loss: 0.635647\n",
      "Epoch: 223, Loss: 0.628125\n",
      "Epoch: 224, Loss: 0.290275\n",
      "Epoch: 225, Loss: 0.365459\n",
      "Epoch: 226, Loss: 0.629916\n",
      "Epoch: 227, Loss: 0.528280\n",
      "Epoch: 228, Loss: 0.819784\n",
      "Epoch: 229, Loss: 0.338771\n",
      "Epoch: 230, Loss: 0.373368\n",
      "Epoch: 231, Loss: 0.608297\n",
      "Epoch: 232, Loss: 0.246031\n",
      "Epoch: 233, Loss: 0.553438\n",
      "Epoch: 234, Loss: 0.369214\n",
      "Epoch: 235, Loss: 0.699541\n",
      "Epoch: 236, Loss: 0.183761\n",
      "Epoch: 237, Loss: 0.438841\n",
      "Epoch: 238, Loss: 0.509131\n",
      "Epoch: 239, Loss: 1.098894\n",
      "Epoch: 240, Loss: 0.539402\n",
      "Epoch: 241, Loss: 0.385514\n",
      "Epoch: 242, Loss: 0.453341\n",
      "Epoch: 243, Loss: 0.493940\n",
      "Epoch: 244, Loss: 0.188525\n",
      "Epoch: 245, Loss: 0.252908\n",
      "Epoch: 246, Loss: 0.588154\n",
      "Epoch: 247, Loss: 0.283773\n",
      "Epoch: 248, Loss: 0.559076\n",
      "Epoch: 249, Loss: 0.150551\n",
      "Epoch: 250, Loss: 0.625747\n",
      "Epoch: 251, Loss: 0.347172\n",
      "Epoch: 252, Loss: 0.396733\n",
      "Epoch: 253, Loss: 0.290457\n",
      "Epoch: 254, Loss: 0.446632\n",
      "Epoch: 255, Loss: 0.402010\n",
      "Epoch: 256, Loss: 0.632027\n",
      "Epoch: 257, Loss: 0.297519\n",
      "Epoch: 258, Loss: 0.436574\n",
      "Epoch: 259, Loss: 0.242904\n",
      "Epoch: 260, Loss: 0.389899\n",
      "Epoch: 261, Loss: 0.576993\n",
      "Epoch: 262, Loss: 0.352625\n",
      "Epoch: 263, Loss: 0.354821\n",
      "Epoch: 264, Loss: 0.643594\n",
      "Epoch: 265, Loss: 0.168519\n",
      "Epoch: 266, Loss: 0.292328\n",
      "Epoch: 267, Loss: 0.528503\n",
      "Epoch: 268, Loss: 0.417787\n",
      "Epoch: 269, Loss: 0.708829\n",
      "Epoch: 270, Loss: 0.368958\n",
      "Epoch: 271, Loss: 0.322156\n",
      "Epoch: 272, Loss: 0.488848\n",
      "Epoch: 273, Loss: 0.182474\n",
      "Epoch: 274, Loss: 0.676838\n",
      "Epoch: 275, Loss: 0.541296\n",
      "Epoch: 276, Loss: 0.378014\n",
      "Epoch: 277, Loss: 0.592173\n",
      "Epoch: 278, Loss: 0.323611\n",
      "Epoch: 279, Loss: 0.248522\n",
      "Epoch: 280, Loss: 0.180634\n",
      "Epoch: 281, Loss: 0.373205\n",
      "Epoch: 282, Loss: 0.328888\n",
      "Epoch: 283, Loss: 0.380906\n",
      "Epoch: 284, Loss: 0.485328\n",
      "Epoch: 285, Loss: 0.330332\n",
      "Epoch: 286, Loss: 0.213203\n",
      "Epoch: 287, Loss: 0.281619\n",
      "Epoch: 288, Loss: 0.405740\n",
      "Epoch: 289, Loss: 0.152216\n",
      "Epoch: 290, Loss: 0.613148\n",
      "Epoch: 291, Loss: 0.339795\n",
      "Epoch: 292, Loss: 0.443221\n",
      "Epoch: 293, Loss: 0.402086\n",
      "Epoch: 294, Loss: 0.330243\n",
      "Epoch: 295, Loss: 0.273464\n",
      "Epoch: 296, Loss: 0.252808\n",
      "Epoch: 297, Loss: 0.326312\n",
      "Epoch: 298, Loss: 0.194434\n",
      "Epoch: 299, Loss: 0.258248\n",
      "Total Time: 1854052 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.perf_counter_ns()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "end_time = time.perf_counter_ns()\n",
    "\n",
    "total_time_ms = (end_time - start_time) / 1000000\n",
    "\n",
    "print(\"Total Time: %d ms\" % (total_time_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93420e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.4835\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(tensor_cifar10_val, batch_size=64, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a61f1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "n_out = 10\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512,512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512,512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, n_out),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca43f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.115163\n",
      "Epoch: 1, Loss: 1.751902\n",
      "Epoch: 2, Loss: 1.915663\n",
      "Epoch: 3, Loss: 1.784431\n",
      "Epoch: 4, Loss: 1.837538\n",
      "Epoch: 5, Loss: 1.549647\n",
      "Epoch: 6, Loss: 1.499068\n",
      "Epoch: 7, Loss: 1.673488\n",
      "Epoch: 8, Loss: 2.592686\n",
      "Epoch: 9, Loss: 1.568397\n",
      "Epoch: 10, Loss: 1.920245\n",
      "Epoch: 11, Loss: 1.327689\n",
      "Epoch: 12, Loss: 1.540429\n",
      "Epoch: 13, Loss: 1.638968\n",
      "Epoch: 14, Loss: 1.742757\n",
      "Epoch: 15, Loss: 1.428038\n",
      "Epoch: 16, Loss: 1.589386\n",
      "Epoch: 17, Loss: 1.340539\n",
      "Epoch: 18, Loss: 1.623624\n",
      "Epoch: 19, Loss: 1.431394\n",
      "Epoch: 20, Loss: 1.146482\n",
      "Epoch: 21, Loss: 1.330903\n",
      "Epoch: 22, Loss: 1.330649\n",
      "Epoch: 23, Loss: 1.625561\n",
      "Epoch: 24, Loss: 1.298224\n",
      "Epoch: 25, Loss: 1.736050\n",
      "Epoch: 26, Loss: 1.334963\n",
      "Epoch: 27, Loss: 1.438913\n",
      "Epoch: 28, Loss: 1.745754\n",
      "Epoch: 29, Loss: 1.502688\n",
      "Epoch: 30, Loss: 1.625713\n",
      "Epoch: 31, Loss: 1.712628\n",
      "Epoch: 32, Loss: 1.392244\n",
      "Epoch: 33, Loss: 1.776826\n",
      "Epoch: 34, Loss: 1.675822\n",
      "Epoch: 35, Loss: 1.416869\n",
      "Epoch: 36, Loss: 1.295799\n",
      "Epoch: 37, Loss: 1.488979\n",
      "Epoch: 38, Loss: 1.317213\n",
      "Epoch: 39, Loss: 0.936151\n",
      "Epoch: 40, Loss: 1.968850\n",
      "Epoch: 41, Loss: 1.354556\n",
      "Epoch: 42, Loss: 1.187716\n",
      "Epoch: 43, Loss: 1.091134\n",
      "Epoch: 44, Loss: 1.216171\n",
      "Epoch: 45, Loss: 1.098467\n",
      "Epoch: 46, Loss: 1.077710\n",
      "Epoch: 47, Loss: 1.093158\n",
      "Epoch: 48, Loss: 1.599285\n",
      "Epoch: 49, Loss: 1.249671\n",
      "Epoch: 50, Loss: 1.243648\n",
      "Epoch: 51, Loss: 1.295992\n",
      "Epoch: 52, Loss: 1.145626\n",
      "Epoch: 53, Loss: 0.991797\n",
      "Epoch: 54, Loss: 1.432019\n",
      "Epoch: 55, Loss: 1.511058\n",
      "Epoch: 56, Loss: 1.041856\n",
      "Epoch: 57, Loss: 1.156557\n",
      "Epoch: 58, Loss: 0.970406\n",
      "Epoch: 59, Loss: 1.253737\n",
      "Epoch: 60, Loss: 1.359633\n",
      "Epoch: 61, Loss: 2.254734\n",
      "Epoch: 62, Loss: 1.115074\n",
      "Epoch: 63, Loss: 1.048198\n",
      "Epoch: 64, Loss: 2.010893\n",
      "Epoch: 65, Loss: 0.927699\n",
      "Epoch: 66, Loss: 1.051700\n",
      "Epoch: 67, Loss: 1.364006\n",
      "Epoch: 68, Loss: 1.164230\n",
      "Epoch: 69, Loss: 0.768513\n",
      "Epoch: 70, Loss: 1.219697\n",
      "Epoch: 71, Loss: 0.832564\n",
      "Epoch: 72, Loss: 0.488606\n",
      "Epoch: 73, Loss: 1.288034\n",
      "Epoch: 74, Loss: 1.075577\n",
      "Epoch: 75, Loss: 0.944574\n",
      "Epoch: 76, Loss: 0.709491\n",
      "Epoch: 77, Loss: 1.125823\n",
      "Epoch: 78, Loss: 0.807990\n",
      "Epoch: 79, Loss: 1.035702\n",
      "Epoch: 80, Loss: 0.859532\n",
      "Epoch: 81, Loss: 0.624199\n",
      "Epoch: 82, Loss: 1.619502\n",
      "Epoch: 83, Loss: 0.811637\n",
      "Epoch: 84, Loss: 0.796373\n",
      "Epoch: 85, Loss: 1.188763\n",
      "Epoch: 86, Loss: 0.925690\n",
      "Epoch: 87, Loss: 1.397365\n",
      "Epoch: 88, Loss: 0.790544\n",
      "Epoch: 89, Loss: 1.249314\n",
      "Epoch: 90, Loss: 1.119051\n",
      "Epoch: 91, Loss: 1.203561\n",
      "Epoch: 92, Loss: 0.897359\n",
      "Epoch: 93, Loss: 0.965140\n",
      "Epoch: 94, Loss: 0.470243\n",
      "Epoch: 95, Loss: 1.242216\n",
      "Epoch: 96, Loss: 1.235495\n",
      "Epoch: 97, Loss: 1.034608\n",
      "Epoch: 98, Loss: 0.722293\n",
      "Epoch: 99, Loss: 0.722247\n",
      "Epoch: 100, Loss: 1.109689\n",
      "Epoch: 101, Loss: 1.388607\n",
      "Epoch: 102, Loss: 0.882379\n",
      "Epoch: 103, Loss: 0.685311\n",
      "Epoch: 104, Loss: 1.055370\n",
      "Epoch: 105, Loss: 1.180807\n",
      "Epoch: 106, Loss: 0.538588\n",
      "Epoch: 107, Loss: 1.005379\n",
      "Epoch: 108, Loss: 0.395915\n",
      "Epoch: 109, Loss: 0.625577\n",
      "Epoch: 110, Loss: 1.015346\n",
      "Epoch: 111, Loss: 0.884789\n",
      "Epoch: 112, Loss: 0.593988\n",
      "Epoch: 113, Loss: 0.758708\n",
      "Epoch: 114, Loss: 0.733719\n",
      "Epoch: 115, Loss: 1.083988\n",
      "Epoch: 116, Loss: 0.707358\n",
      "Epoch: 117, Loss: 0.607230\n",
      "Epoch: 118, Loss: 0.839141\n",
      "Epoch: 119, Loss: 0.940939\n",
      "Epoch: 120, Loss: 0.739529\n",
      "Epoch: 121, Loss: 0.521046\n",
      "Epoch: 122, Loss: 0.780763\n",
      "Epoch: 123, Loss: 0.806312\n",
      "Epoch: 124, Loss: 0.719754\n",
      "Epoch: 125, Loss: 0.712315\n",
      "Epoch: 126, Loss: 1.308253\n",
      "Epoch: 127, Loss: 0.933739\n",
      "Epoch: 128, Loss: 1.349290\n",
      "Epoch: 129, Loss: 0.838871\n",
      "Epoch: 130, Loss: 0.759940\n",
      "Epoch: 131, Loss: 0.402995\n",
      "Epoch: 132, Loss: 0.297944\n",
      "Epoch: 133, Loss: 0.436109\n",
      "Epoch: 134, Loss: 0.651703\n",
      "Epoch: 135, Loss: 0.637684\n",
      "Epoch: 136, Loss: 0.647317\n",
      "Epoch: 137, Loss: 0.713969\n",
      "Epoch: 138, Loss: 0.336811\n",
      "Epoch: 139, Loss: 0.263234\n",
      "Epoch: 140, Loss: 0.882000\n",
      "Epoch: 141, Loss: 0.334373\n",
      "Epoch: 142, Loss: 0.642208\n",
      "Epoch: 143, Loss: 0.576786\n",
      "Epoch: 144, Loss: 0.534557\n",
      "Epoch: 145, Loss: 0.431268\n",
      "Epoch: 146, Loss: 0.955445\n",
      "Epoch: 147, Loss: 0.711590\n",
      "Epoch: 148, Loss: 0.304513\n",
      "Epoch: 149, Loss: 0.707490\n",
      "Epoch: 150, Loss: 0.670600\n",
      "Epoch: 151, Loss: 0.450639\n",
      "Epoch: 152, Loss: 0.630712\n",
      "Epoch: 153, Loss: 0.848320\n",
      "Epoch: 154, Loss: 0.434247\n",
      "Epoch: 155, Loss: 0.533050\n",
      "Epoch: 156, Loss: 0.187240\n",
      "Epoch: 157, Loss: 0.877416\n",
      "Epoch: 158, Loss: 0.182821\n",
      "Epoch: 159, Loss: 0.635784\n",
      "Epoch: 160, Loss: 0.159671\n",
      "Epoch: 161, Loss: 0.338118\n",
      "Epoch: 162, Loss: 0.503776\n",
      "Epoch: 163, Loss: 0.526031\n",
      "Epoch: 164, Loss: 1.229683\n",
      "Epoch: 165, Loss: 0.255360\n",
      "Epoch: 166, Loss: 1.060402\n",
      "Epoch: 167, Loss: 0.082268\n",
      "Epoch: 168, Loss: 0.821968\n",
      "Epoch: 169, Loss: 0.112436\n",
      "Epoch: 170, Loss: 0.208103\n",
      "Epoch: 171, Loss: 0.583380\n",
      "Epoch: 172, Loss: 0.170103\n",
      "Epoch: 173, Loss: 0.232492\n",
      "Epoch: 174, Loss: 0.144060\n",
      "Epoch: 175, Loss: 0.290372\n",
      "Epoch: 176, Loss: 0.624754\n",
      "Epoch: 177, Loss: 0.327001\n",
      "Epoch: 178, Loss: 0.224023\n",
      "Epoch: 179, Loss: 0.053116\n",
      "Epoch: 180, Loss: 0.503849\n",
      "Epoch: 181, Loss: 0.777950\n",
      "Epoch: 182, Loss: 0.352952\n",
      "Epoch: 183, Loss: 0.138178\n",
      "Epoch: 184, Loss: 0.107446\n",
      "Epoch: 185, Loss: 0.265544\n",
      "Epoch: 186, Loss: 0.251518\n",
      "Epoch: 187, Loss: 0.053693\n",
      "Epoch: 188, Loss: 0.073185\n",
      "Epoch: 189, Loss: 0.295118\n",
      "Epoch: 190, Loss: 0.140065\n",
      "Epoch: 191, Loss: 0.507618\n",
      "Epoch: 192, Loss: 0.130875\n",
      "Epoch: 193, Loss: 0.157370\n",
      "Epoch: 194, Loss: 0.236836\n",
      "Epoch: 195, Loss: 0.074732\n",
      "Epoch: 196, Loss: 0.223757\n",
      "Epoch: 197, Loss: 0.060873\n",
      "Epoch: 198, Loss: 0.068998\n",
      "Epoch: 199, Loss: 0.090922\n",
      "Epoch: 200, Loss: 0.041024\n",
      "Epoch: 201, Loss: 0.104707\n",
      "Epoch: 202, Loss: 0.102976\n",
      "Epoch: 203, Loss: 0.094099\n",
      "Epoch: 204, Loss: 0.170764\n",
      "Epoch: 205, Loss: 0.137562\n",
      "Epoch: 206, Loss: 0.045926\n",
      "Epoch: 207, Loss: 0.065357\n",
      "Epoch: 208, Loss: 0.222886\n",
      "Epoch: 209, Loss: 0.414661\n",
      "Epoch: 210, Loss: 0.016114\n",
      "Epoch: 211, Loss: 0.075559\n",
      "Epoch: 212, Loss: 0.034966\n",
      "Epoch: 213, Loss: 0.094486\n",
      "Epoch: 214, Loss: 0.019699\n",
      "Epoch: 215, Loss: 0.043653\n",
      "Epoch: 216, Loss: 0.026297\n",
      "Epoch: 217, Loss: 0.048118\n",
      "Epoch: 218, Loss: 0.157449\n",
      "Epoch: 219, Loss: 0.081494\n",
      "Epoch: 220, Loss: 0.034298\n",
      "Epoch: 221, Loss: 0.513237\n",
      "Epoch: 222, Loss: 0.143516\n",
      "Epoch: 223, Loss: 0.137239\n",
      "Epoch: 224, Loss: 0.033649\n",
      "Epoch: 225, Loss: 0.066207\n",
      "Epoch: 226, Loss: 0.065968\n",
      "Epoch: 227, Loss: 0.011520\n",
      "Epoch: 228, Loss: 0.006978\n",
      "Epoch: 229, Loss: 0.685443\n",
      "Epoch: 230, Loss: 0.023329\n",
      "Epoch: 231, Loss: 0.032679\n",
      "Epoch: 232, Loss: 0.004614\n",
      "Epoch: 233, Loss: 0.037189\n",
      "Epoch: 234, Loss: 0.013626\n",
      "Epoch: 235, Loss: 0.014431\n",
      "Epoch: 236, Loss: 0.120357\n",
      "Epoch: 237, Loss: 0.003828\n",
      "Epoch: 238, Loss: 0.032108\n",
      "Epoch: 239, Loss: 0.013880\n",
      "Epoch: 240, Loss: 0.021504\n",
      "Epoch: 241, Loss: 2.282382\n",
      "Epoch: 242, Loss: 0.013947\n",
      "Epoch: 243, Loss: 0.007243\n",
      "Epoch: 244, Loss: 0.007624\n",
      "Epoch: 245, Loss: 0.035289\n",
      "Epoch: 246, Loss: 0.017636\n",
      "Epoch: 247, Loss: 0.011204\n",
      "Epoch: 248, Loss: 0.010803\n",
      "Epoch: 249, Loss: 0.005407\n",
      "Epoch: 250, Loss: 0.008812\n",
      "Epoch: 251, Loss: 0.021598\n",
      "Epoch: 252, Loss: 0.003650\n",
      "Epoch: 253, Loss: 0.008511\n",
      "Epoch: 254, Loss: 0.009525\n",
      "Epoch: 255, Loss: 0.017236\n",
      "Epoch: 256, Loss: 0.334656\n",
      "Epoch: 257, Loss: 0.010957\n",
      "Epoch: 258, Loss: 0.012647\n",
      "Epoch: 259, Loss: 0.004823\n",
      "Epoch: 260, Loss: 0.005350\n",
      "Epoch: 261, Loss: 0.026355\n",
      "Epoch: 262, Loss: 0.056878\n",
      "Epoch: 263, Loss: 0.074308\n",
      "Epoch: 264, Loss: 0.007374\n",
      "Epoch: 265, Loss: 0.003657\n",
      "Epoch: 266, Loss: 0.023089\n",
      "Epoch: 267, Loss: 0.001314\n",
      "Epoch: 268, Loss: 0.006654\n",
      "Epoch: 269, Loss: 0.009537\n",
      "Epoch: 270, Loss: 0.007304\n",
      "Epoch: 271, Loss: 0.008225\n",
      "Epoch: 272, Loss: 0.002192\n",
      "Epoch: 273, Loss: 0.001762\n",
      "Epoch: 274, Loss: 0.013383\n",
      "Epoch: 275, Loss: 0.007891\n",
      "Epoch: 276, Loss: 0.005040\n",
      "Epoch: 277, Loss: 0.008441\n",
      "Epoch: 278, Loss: 0.009061\n",
      "Epoch: 279, Loss: 0.002736\n",
      "Epoch: 280, Loss: 0.003687\n",
      "Epoch: 281, Loss: 0.015334\n",
      "Epoch: 282, Loss: 0.006718\n",
      "Epoch: 283, Loss: 0.035858\n",
      "Epoch: 284, Loss: 0.015986\n",
      "Epoch: 285, Loss: 0.006829\n",
      "Epoch: 286, Loss: 0.009410\n",
      "Epoch: 287, Loss: 0.003691\n",
      "Epoch: 288, Loss: 0.003969\n",
      "Epoch: 289, Loss: 0.000905\n",
      "Epoch: 290, Loss: 0.017244\n",
      "Epoch: 291, Loss: 0.005462\n",
      "Epoch: 292, Loss: 0.005387\n",
      "Epoch: 293, Loss: 0.002870\n",
      "Epoch: 294, Loss: 0.004865\n",
      "Epoch: 295, Loss: 0.004509\n",
      "Epoch: 296, Loss: 0.002718\n",
      "Epoch: 297, Loss: 0.002320\n",
      "Epoch: 298, Loss: 0.003505\n",
      "Epoch: 299, Loss: 0.004526\n",
      "Total Time: 2344956 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.perf_counter_ns()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "end_time = time.perf_counter_ns()\n",
    "\n",
    "total_time_ms = (end_time - start_time) / 1000000\n",
    "\n",
    "print(\"Total Time: %d ms\" % (total_time_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ea1850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.5263\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(tensor_cifar10_val, batch_size=64, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c881a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
